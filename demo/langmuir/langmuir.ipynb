{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import physo\n",
    "from physo.task import benchmark\n",
    "from physo.learn import monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 10**np.linspace(0, 8, 100)\n",
    "def langmuir(b, q):\n",
    "    bp = b*p\n",
    "    return q * b * p / (1 + b * p)\n",
    "\n",
    "X = torch.Tensor(p).reshape(1, -1)\n",
    "y = torch.Tensor(langmuir(1e-4, 2.0))\n",
    "const1 = torch.Tensor([1.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# ax.set_xscale(\"log\")\n",
    "b1, q1 = 1e-7, 1.0\n",
    "b2, q2 = 1e-6, 1.0\n",
    "ax.plot(p, langmuir(b1, q1), label=\"1\")\n",
    "ax.plot(p, langmuir(b2, q2), label=\"2\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [length, mass, time]\n",
    "args_make_tokens = {\n",
    "                # operations\n",
    "                \"op_names\"             : [\"mul\", \"add\", \"sub\", \"div\", \"inv\", \"neg\"],\n",
    "                \"use_protected_ops\"    : True,\n",
    "                # input variables\n",
    "                \"input_var_ids\"        : {\"p\" : 0         ,},\n",
    "                \"input_var_units\"      : {\"p\" : [-2, 0, 1] ,},\n",
    "                \"input_var_complexity\" : {\"p\" : 1.        ,},\n",
    "                # constants\n",
    "                \"constants\"            : {\"1\" : const1    , },\n",
    "                \"constants_units\"      : {\"1\" : [0, 0, 0] , },\n",
    "                \"constants_complexity\" : {\"1\" : 1.        , },\n",
    "                # free constants\n",
    "                \"free_constants\"            : {\"b\", \"qsat\"},\n",
    "                \"free_constants_init_val\"   : {\"b\" : 1., \"qsat\" : 1.},\n",
    "                \"free_constants_units\"      : {\"b\" : [2, 0, -1] , \"qsat\" : [0, 1, 0]},\n",
    "                \"free_constants_complexity\" : {\"b\" : 1., \"qsat\" : 1.},\n",
    "                    }\n",
    "\n",
    "library_config = {\"args_make_tokens\"  : args_make_tokens,\n",
    "                  \"superparent_units\" : [0, 1, 0],\n",
    "                  \"superparent_name\"  : \"q\",\n",
    "                }\n",
    "\n",
    "reward_config = {\n",
    "                 \"reward_function\"     : physo.physym.reward.SquashedNRMSE, \n",
    "                 \"zero_out_unphysical\" : True,\n",
    "                 \"zero_out_duplicates\" : False,\n",
    "                 \"keep_lowest_complexity_duplicate\" : False,\n",
    "                 \"parallel_mode\" : True,\n",
    "                 \"n_cpus\"        : None,\n",
    "                }\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "BATCH_SIZE = int(1e3)\n",
    "MAX_LENGTH = 16\n",
    "GET_OPTIMIZER = lambda model : torch.optim.Adam(\n",
    "                                    model.parameters(),                \n",
    "                                    lr=0.0025, #0.001, #0.0050, #0.0005, #1,  #lr=0.0025\n",
    "                                                )\n",
    "\n",
    "learning_config = {\n",
    "    # Batch related\n",
    "    'batch_size'       : BATCH_SIZE,\n",
    "    'max_time_step'    : MAX_LENGTH,\n",
    "    'n_epochs'         : int(1e2),\n",
    "    # Loss related\n",
    "    'gamma_decay'      : 0.7,\n",
    "    'entropy_weight'   : 0.005,\n",
    "    # Reward related\n",
    "    'risk_factor'      : 0.05,\n",
    "    'rewards_computer' : physo.physym.reward.make_RewardsComputer (**reward_config),\n",
    "    # Optimizer\n",
    "    'get_optimizer'    : GET_OPTIMIZER,\n",
    "    'observe_units'    : True,\n",
    "}\n",
    "\n",
    "free_const_opti_args = {\n",
    "            'loss'   : \"MSE\",\n",
    "            'method' : 'LBFGS',\n",
    "            'method_args': {\n",
    "                        'n_steps' : 15,\n",
    "                        'tol'     : 1e-6,\n",
    "                        'lbfgs_func_args' : {\n",
    "                            'max_iter'       : 4,\n",
    "                            'line_search_fn' : \"strong_wolfe\",\n",
    "                                             },\n",
    "                            },\n",
    "        }\n",
    "\n",
    "priors_config  = [\n",
    "                #(\"UniformArityPrior\", None),\n",
    "                # LENGTH RELATED\n",
    "                (\"HardLengthPrior\"  , {\"min_length\": 2, \"max_length\": MAX_LENGTH, }),\n",
    "                (\"SoftLengthPrior\"  , {\"length_loc\": 3, \"scale\": 5, }),\n",
    "                # RELATIONSHIPS RELATED\n",
    "                (\"NoUselessInversePrior\"  , None),\n",
    "                (\"PhysicalUnitsPrior\", {\"prob_eps\": np.finfo(np.float32).eps}), # PHYSICALITY\n",
    "                #(\"NestedFunctions\", {\"functions\":[\"exp\",], \"max_nesting\" : 1}),\n",
    "                #(\"NestedFunctions\", {\"functions\":[\"log\",], \"max_nesting\" : 1}),\n",
    "                #(\"NestedTrigonometryPrior\", {\"max_nesting\" : 1}),           \n",
    "                #(\"OccurrencesPrior\", {\"targets\" : [\"1\",], \"max\" : [3,] }),\n",
    "                 ]\n",
    "\n",
    "cell_config = {\n",
    "    \"hidden_size\" : 32,\n",
    "    \"n_layers\"    : 1,\n",
    "    \"is_lobotomized\" : False,\n",
    "}\n",
    "\n",
    "save_path_training_curves = 'demo_curves.png'\n",
    "save_path_log             = 'demo.log'\n",
    "\n",
    "run_logger     = monitoring.RunLogger(save_path = save_path_log, \n",
    "                                      do_save = True)\n",
    "\n",
    "run_visualiser = monitoring.RunVisualiser (epoch_refresh_rate = 10,\n",
    "                                           save_path = save_path_training_curves,\n",
    "                                           do_show   = False,\n",
    "                                           do_prints = True,\n",
    "                                           do_save   = True, )\n",
    "\n",
    "run_config = {\n",
    "    \"learning_config\"      : learning_config,\n",
    "    \"reward_config\"        : reward_config,\n",
    "    \"free_const_opti_args\" : free_const_opti_args,\n",
    "    \"library_config\"       : library_config,\n",
    "    \"priors_config\"        : priors_config,\n",
    "    \"cell_config\"          : cell_config,\n",
    "    \"run_logger\"           : run_logger,\n",
    "    \"run_visualiser\"       : run_visualiser,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.dummy_epoch(X, y, run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, candidates = physo.fit(X, y, run_config, stop_reward=0.999, stop_after_n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto_front_complexities, pareto_front_programs, pareto_front_r, pareto_front_rmse = run_logger.get_pareto_front()\n",
    "for prog in pareto_front_programs:\n",
    "    prog.show_infix(do_simplify=True)\n",
    "    free_consts = prog.free_const_values.detach().cpu().numpy()\n",
    "    for i in range (len(free_consts)):\n",
    "        print(\"%s = %f\"%(prog.library.free_const_names[i], free_consts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compchem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
